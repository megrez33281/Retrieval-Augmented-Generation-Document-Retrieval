專案提案：課程作業問答助理
1. Introduction (簡介)
問題概述(Problem Overview)：
學生在學習過程中，常需花費大量時間閱讀冗長、格式多樣的作業說明文件以尋找關鍵資訊（例如：截止日期、評分標準、環境設定等）。
當資訊分散在多份文件中，或深埋於數頁內容之中時，這個過程會變得非常耗時且效率低下。

重要性(Importance)：
一個能夠快速、準確回答學生關於作業問題的智慧系統，可以極大地節省學生的時間與精力，讓他們更專注於作業本身的核心挑戰，從而提升學習成效與課程體驗


IR任務(IR Tasks)：
本專案旨在建立一個以「檢索增強生成 (RAG)」框架為核心的問答系統
它將直接應對課程要求的兩大主題 ：
	領域專業的RAG(Domain-Specialized RAG)：
		專注於「課程作業說明」這個高度特定的領域，打造一個精準的知識問答模型

	多模態檢索(Multimodal Retrieval)：
		專案初期將以文字為核心，但整體框架的設計將具備擴展性，為未來整合影片（語音 ASR、視覺 OCR）等多模態資料流打下基礎

2. Dataset (資料集)
資料來源與領域(Source and Domain)：
	我們計畫使用的主要資料集，將是**本課程**所發布的官方作業與專題說明文件。
	
資料大小(Size)：
	初期的資料集將包含本課程的3份說明文件，包括作業+期末專題要求
	雖然文件數量不多，但這使我們能夠進行深入、細緻的系統分析與評估

擴展計畫(Expansion Plan)：
	在確保深度的前提下，為了測試系統的泛化能力，可以嘗試在專案後期，引入1-2份其他課程（例如：機器學習）的作業說明文件作為額外的測試集


3. Evaluation Methods(評估方法)

	* Quantitative Evaluation（量化評估）
		1. Retrieval Relevance
			使用Recall@k或MRR衡量檢索出的Chunk是否包含正確文件 
			若正確文件出現在前k筆結果中，則視為成功檢索

		2. Answer Accuracy
			基於人工建立的標準問答集，使用ChatGPT（LLM-as-a-Judge）進行自動化評估  
			利用固定的Prompt讓其在三個面向進行打分：  
				Correctness：回答內容是否與標準答案一致。 
				Faithfulness：回答是否僅根據檢索文件內容生成、無幻覺
				Clarity：回答是否語句通順、易於理解 
			每個面向的分數將自動化取得，並取平均作為最終的生成評估結果


	* Qualitative Evaluation（質化評估）
		針對系統回答錯誤的案例進行錯誤分析，探討失敗原因，例如：  
			檢索階段未能找到正確的Chunk（retrieval error）
			模型生成出與文件不符的內容（hallucination）
			引用錯誤或回答不完整（citation / coverage issue）
		這些質化分析結果將作為改進系統與調整prompt的依據

		
		
4. Method
	核心框架
		基於檢索增強生成(Retrieval-Augmented Generation, RAG)框架進行開發

	資料結構化流程：
		(1)文本分塊(Chunking)
			把一份很長的文件，自動切成很多個小的有邏輯的段落（可選擇依長度切割或依語意切割）
			用這個技術把幾頁長的作業說明，自動分解成數十個獨立的「知識卡片」，方便後續處理
			
		(2)附加來源元數據(Metadata Attaching)
			為每一筆切分好的資料，貼上一個「來源標籤」，即為知識卡片加上出處，如：這張卡片來自期末專題要求.pdf 的第2頁，第3段
			確保系統回答問題時能夠產生附加答案來源的回答
			
		(3)語義向量化(Vectorization)
			利用嵌入模型將每張知識卡片的內容傳換成Embedding，意思相近的卡片在特徵空間中也會非常靠近，例如，「繳交期限」和「due date」就會非常靠近。
			當使用者問「報告何時截止？」時，系統會先把這個問題也轉換成一個Embedding，然後去地圖上尋找座標最接近的幾張知識卡片。
			
			
			
			
			
靈感原文：
我在想是不是可以用Chunking的技術把文本切割成多個chunk（依不同的技術可能切成同大小、不同大小）
利用語意分析或者關鍵字分析簡介該Chunk的內容，這樣資料就會被分割成很多格式相同的資料：
　　{ 
　　　　　"關鍵字": ..., 
　　　　　"內容":...
　　} 
可以串接LLM幫忙從使用者的問題中提取關鍵字，然後再搜索匹配資料庫中的關鍵字抓出對應的資料塊
甚至回答問題的時候可以把資料塊丟給LLM讓其根據資料內容回答問題
這樣應該就可以很容易地根據使用者的問題檢索到相應的Chunk，並藉此回答問題
即使不同科目的作業要求會不一樣，但是應該大部分的形式都限制在文字和圖片的格式
只要能把資料切分，然後加上簡短的對資料快的簡介或關鍵字，應該就能用於與使用者輸入的問題的慣見自進行匹配
另外，這麼做與直接把資料丟給LLM的區別在於LLM通常有長度限制，檔案較大的作業要求會無法交由LLM檢索以及可以提升LLM回答問題的精度


用這種方法嘗試對我們這門課的資料進行處理，或許能在滿足深度的同時嘗試增加泛化能力



	
	
